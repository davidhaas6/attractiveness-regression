{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYav5m8BUxDr"
   },
   "source": [
    "# Do attractive Redditors get more upvotes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wx2xJDDsdrRG"
   },
   "source": [
    "**Group 17**: **Jack Silk** (jsilk13), **David Haas** (dhaas6), **Spencer Mullinix** (mullisd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNXoQ73-U78H"
   },
   "source": [
    "<b>Is there a correlation between the attractiveness of the redditor and the number of upvotes they get?</b>  We believe that the higher the physical attractiveness of the redditor is, the more upvotes they will receive.  Whether it is conscious or subconscious, we think that to some degree, users decide whether to upvote a post or not based on the attractivness of the poster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYlpPWr5U8Gz"
   },
   "source": [
    "<b>How will we determine the physical attractiveness of a Reddit user?</b>  We are going to use a facial recognition algorithm to apply a rating of physical attractiveness to the user.  Dlib's facial recognition tool creates a vector of 128 values based on the features of a person's face.  We will use this vector to create our rating scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrx75eguLY4c"
   },
   "outputs": [],
   "source": [
    "# Sciences\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "# Scraping\n",
    "import praw, psaw\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "# Other\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import traceback\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMWqAc8GNX38"
   },
   "outputs": [],
   "source": [
    "def encode_image(img_path):\n",
    "    \"\"\" Returns encoding\n",
    "    \"\"\"\n",
    "    img = face_recognition.load_image_file(img_path)\n",
    "\n",
    "    # Search for faces and encode\n",
    "    face_locs = face_recognition.face_locations(img)\n",
    "    if len(face_locs) > 0:\n",
    "        return face_recognition.face_encodings(img, known_face_locations=face_locs)\n",
    "    else:\n",
    "        return [np.zeros((128))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ul62TAaBMRd7"
   },
   "outputs": [],
   "source": [
    "# Connect to Reddit and Pushshift\n",
    "reddit_client = praw.Reddit(client_id='6ZOjAwnqUehb5Q', \n",
    "                            client_secret='gc4rkA50yNq9pBn1diU11Xj1nKY', \n",
    "                            user_agent='ffinder_test')\n",
    "api = psaw.PushshiftAPI(reddit_client)\n",
    "deleted_reddit, deleted_imgur = pickle.load(open('./content/deleted_binaries.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_LIYbUIfwFz"
   },
   "source": [
    "Data Gathered:\n",
    "\n",
    "\n",
    "*   Facial encodings of pictures containing faces\n",
    "*   URLs to Reddit post and direct image\n",
    "*   The score for that post (upvotes - downvotes)\n",
    "\n",
    "generate_encodings() makes Pushshift API calls, collecting results for the inputted subreddit over a given time period. Each result is passed into process_image() which encodes any present faces and extracts the metadata (URLs and score).\n",
    "\n",
    "After the face_limit is met in generate_encodings, the function returns an two arrays, one for the encodings and one for the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7_8QGeKPvet"
   },
   "outputs": [],
   "source": [
    "def is_img(path):\n",
    "    return path[-4:] in {\".png\", '.jpg'}\n",
    "\n",
    "\n",
    "def process_image(api_result):\n",
    "    \"\"\" Downloads image from the Pushshift api entry and encodes it if there are faces present\n",
    "        Arguments:\n",
    "            api_result (psaw api result): A single entry in the psaw search query result\n",
    "        Returns:\n",
    "            False if unsuccessful\n",
    "            tuple of encoding and metadata if successfull\n",
    "    \"\"\"\n",
    "    if not is_img(api_result.url):  return False\n",
    "\n",
    "    # Fetch and load image\n",
    "    try:\n",
    "        img_bytes = requests.get(api_result.url).content\n",
    "        if img_bytes == deleted_imgur or img_bytes == deleted_reddit:  return False\n",
    "        img = face_recognition.load_image_file(BytesIO(img_bytes))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    # Search for faces and encode\n",
    "    face_locs = face_recognition.face_locations(img)\n",
    "    if len(face_locs) > 0:\n",
    "        encodings = face_recognition.face_encodings(img, known_face_locations=face_locs)\n",
    "        return encodings, (api_result.shortlink, api_result.url, api_result.score)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def generate_encodings(subreddit, face_limit=10e7):\n",
    "    \"\"\" Generates a set of facial encodings from each valid image on a subreddit\n",
    "        Given a subreddit, this function collects its images, starting with the most recent in multi-day chunks.\n",
    "        After downloading an image, it is analyzed for faces, and if faces are present it generates an encoding\n",
    "        and stores metadata about the image to be pickled and saved.\n",
    "        \n",
    "        Args:\n",
    "            subreddit (str): The subreddit name to process images from\n",
    "            image_limit (int): The maximum number of images to process.\n",
    "        Returns:\n",
    "            tuple: (A Nx128 matrix of encodings, a list of metadata corresponding by index to each row in the matrix)\n",
    "    \"\"\"\n",
    "\n",
    "    encodings = np.zeros((0,128))\n",
    "    metadata = []\n",
    "    \n",
    "    CHUNK_SIZE = 1 * 86400  # 1 day chunks\n",
    "    chunk_end = datetime.now().timestamp()\n",
    "    chunk_start = chunk_end - CHUNK_SIZE\n",
    "    stop = False\n",
    "\n",
    "    while not stop:\n",
    "        prev_length = encodings.shape[0]\n",
    "        face_data = []\n",
    "        # Process the chunk of api data\n",
    "        try:\n",
    "            chunk_data = api.search_submissions(before=int(chunk_end), after=int(chunk_start), subreddit=subreddit)\n",
    "\n",
    "            # Process the API results for faces\n",
    "            face_data = list(map(process_image, chunk_data))\n",
    "\n",
    "            # Separate and store face_data into encodings and metadata\n",
    "            for entry in face_data:\n",
    "                if type(entry) is not tuple:  continue\n",
    "                enc, meta = entry\n",
    "                encodings = np.vstack((encodings,enc))\n",
    "\n",
    "                num_faces = len(enc)\n",
    "                for i in range(num_faces):\n",
    "                    metadata.append(meta)\n",
    "\n",
    "            # Print results\n",
    "            length = encodings.shape[0]\n",
    "            num_added = length - prev_length\n",
    "            face_per_img = 0 if len(face_data) == 0 else num_added/len(face_data)\n",
    "            \n",
    "            stop = length >= face_limit or length == prev_length\n",
    "            print(\"%i new faces encoded (avg %.2f faces per image)! Total = %i\" % (num_added, face_per_img, length))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"ERROR: \")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        chunk_end = chunk_start-1\n",
    "        chunk_start = chunk_end - CHUNK_SIZE\n",
    "        \n",
    "    return encodings, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNZn1kpESK40"
   },
   "outputs": [],
   "source": [
    "encodings, metadata = generate_encodings('selfies', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ceREo4rhXHh"
   },
   "source": [
    "With the ability to now collect large amounts of faces from Reddit and encode them, we can focus on the analysis of each encoding, and converting them to a beauty rating (1-5). \n",
    "We split this step between group members so that we could develop different approaches and avoid a bottleneck on this step.\n",
    "\n",
    "First is our linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any predicting, we must train the model off of the [SCUT-FBP5500](https://github.com/HCIILAB/SCUT-FBP5500-Database-Release) Dataset encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build encodings (samples) as inputs to the regression model\n",
    "import glob\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "datapath = './SCUT-FBP5500_v2/Images/*'\n",
    "img_paths = glob.glob(datapath)\n",
    "all_encodings = np.zeros((len(img_paths),128))\n",
    "\n",
    "# Encode\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    encodings = encode_image(img_path)\n",
    "    for enc in encodings:\n",
    "        all_encodings[i,:] = enc\n",
    "        \n",
    "# Save\n",
    "np.save(\"SCUT-encodings.npy\", all_encodings)\n",
    "\n",
    "# Build labels (targets)\n",
    "with open('SCUT-FBP5500_v2/train_test_files/All_labels.txt') as f:\n",
    "    # keys: filenames  //  values: ratings\n",
    "    file_labels = {line.split(' ')[0]:float(line.split(' ')[1].strip()) for line in f.readlines()}\n",
    "    \n",
    "    labels = np.zeros((len(img_paths)))\n",
    "    for i,path in enumerate(img_paths):\n",
    "        _, filename = os.path.split(path) \n",
    "        labels[i] = file_labels[filename]\n",
    "        \n",
    "    np.save(\"SCUT-labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encodings = np.load('SCUT-encodings.npy')\n",
    "labels = np.load('SCUT-labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11003712  0.04569392  0.07832608 ... -0.03538962  0.04172648\n",
      "  -0.00650166]\n",
      " [-0.02509105  0.04950476  0.01658421 ... -0.08789321  0.16508803\n",
      "  -0.02094195]\n",
      " [-0.10630707  0.13151646  0.10914098 ... -0.06461035  0.06733254\n",
      "  -0.01326104]\n",
      " ...\n",
      " [-0.08162953  0.05059871  0.03242504 ... -0.0759866   0.10453327\n",
      "   0.03841674]\n",
      " [-0.09661861  0.05757315  0.07216612 ... -0.05055808 -0.03908116\n",
      "   0.00097661]\n",
      " [-0.10787126  0.06926876  0.1401426  ... -0.00086246 -0.02051616\n",
      "   0.05431798]]\n",
      "[2.066667 3.433333 2.066667 ... 3.983333 1.9      3.833333]\n",
      "Avg Mean Absolute Error: 0.30598227227473007, Std: 0.0049610452935545755\n"
     ]
    }
   ],
   "source": [
    "# Train and score the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(all_encodings, labels)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "scores = cross_val_score(model, all_encodings, labels, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Avg Mean Absolute Error: {0}, Std: {1}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'roastme_1140-122419.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-875df250b9b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the model on /r/roastme encodings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencodings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roastme_1140-122419.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num faces:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean rating (1-5): {:0.2f}, std: {:1.1f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'roastme_1140-122419.pkl'"
     ]
    }
   ],
   "source": [
    "# Run the model on /r/roastme encodings\n",
    "encodings, meta = pickle.load(open('roastme_1140-122419.pkl', 'rb'))\n",
    "print(\"Num faces:\", len(encodings))\n",
    "ratings = model.predict(encodings)\n",
    "print(\"Mean rating (1-5): {:0.2f}, std: {:1.1f}\".format(ratings.mean(), ratings.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.1100e+02, 9.9100e+02, 4.1620e+03, 1.3480e+04, 3.2134e+04,\n",
       "        4.4454e+04, 3.0181e+04, 8.8980e+03, 1.0260e+03, 3.9000e+01]),\n",
       " array([0.92201495, 1.32300042, 1.72398589, 2.12497136, 2.52595683,\n",
       "        2.9269423 , 3.32792777, 3.72891324, 4.12989871, 4.53088418,\n",
       "        4.93186965]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For such a large dataset, one would expect that if beauty, like other human phenotypes, is normally distributed, that the average output would be the median of possible scores (1 through 5). As one can see above, after analyzing 130,000+ faces, our model returns an average rating of 3/5: the median of possible scores.\n",
    "\n",
    "Additionally, upon plotting the calculated ratings one can see that they are organized normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "network = MLPRegressor(validation_fraction = 0, solver='adam', max_iter= 1000).fit(all_encodings, labels)\n",
    "scores = cross_val_score(network, all_encodings, labels, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Avg Mean Absolute Error: {0}, Std: {1}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'roastme_1140-122419.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0a6e30a8d824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the model on /r/roastme encodings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencodings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roastme_1140-122419.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num faces:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean rating (1-5): {:0.2f}, std: {:1.1f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'roastme_1140-122419.pkl'"
     ]
    }
   ],
   "source": [
    "# Run the model on /r/roastme encodings\n",
    "print(\"Num faces:\", len(encodings))\n",
    "ratings = network.predict(encodings)\n",
    "print(\"Mean rating (1-5): {:0.2f}, std: {:1.1f}\".format(ratings.mean(), ratings.std()))\n",
    "plt.hist(ratings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "phase1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
